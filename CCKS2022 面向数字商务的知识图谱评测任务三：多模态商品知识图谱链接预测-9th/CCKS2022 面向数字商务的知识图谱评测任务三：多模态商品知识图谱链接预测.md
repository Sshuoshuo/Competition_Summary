# CCKS2022 面向数字商务的知识图谱评测任务三：多模态商品知识图谱链接预测

竞赛小白第一次参赛，感触是学到了很多，也有很多不能上分时的无奈，分享本次参赛过程中的一些感想与经验，以及一些通用上分Trick。

#### 最终名次

<img src="rank_result.png" alt="image-20220807162751181" style="zoom: 67%;" />

## 目录

- 任务描述
- 数据集描述
- 参赛流程与方案
- Trick分享

## 任务描述

知识图谱一般通过三元组（h,r,t）的形式组织数据，其中h被称为头实体，t为尾实体，r为连接头、尾实体的关系。由于知识图谱构建中部分知识的缺失及知识动态变化等原因，现有的知识图谱通常是不完备的，知识图谱中总是存在关系r下头实体h或者尾实体t缺失的情况。基于知识图谱的链接预测任务，就是已知头实体（或尾实体）和关系的情况下，预测缺失的尾实体（或头实体）的任务。我们在当前任务下所提供的多模态知识图谱的头实体h通常为商品，尾实体t通常为商品所对应相关属性信息，关系r为具体的属性类型。因此在该任务下链接预测指的是，在已知商品h和商品的属性r的情况下，预测商品对应的属性值t的任务。  

## 数据集描述

在训练及验证数据发布阶段，我们会发布包含20万条左右三元组训练集和包含15000条左右query：（头实体，关系，？）的测试集，开发集请选手从训练集中自行划分。训练集train.tsv每行为一个三元组，头实体、关系、尾实体之间用制表符(\t)分隔。具体示例如下：  

**train.tsv**
头实体<\t>关系<\t>尾实体  

**test.tsv**
头实体<\t>关系
头实体中，部分实体提供图片数据，图片数据包含在以实体命名的文件夹中，例如头实体ent_000000，实体对应图片则是images/ent_000000/***。  

**上面是官方给的数据集描述，经过个人分析，实体只是多了图片这一维度的特征，其它的官方没有给出，例如图片的文字描述，若要使用需要自己提取。**

## 参赛流程与方案

### Baseline上传与数据分析

首先看看官方给的方案，跑一遍之后提交结果，看看是否与公布的score有较大的gap。若分数与前排差距不大，可在此baseline上进行修改，因为baseline的数据处理都已经做好，比较省时间专注于方案模型本身。   

然后进行简单的数据分析，本数据都是以匿名三元组的形式给出，三元组的实体与关系只有代号没有具体实际意义，因此对于实体本身的特征只能从图片入手，由于我之前未接触过CV，图片相关的知识完全空白，未来也不打算入CV，所以将大赛的“多模态”扔掉了，自断一臂。那么这个数据集的重要特征就是关系的类型、实体的类型数量，统计出这些基本信息。

### 方案搜索  

接下来就是漫长的方案搜索了。方案需要尽量的SOTA，且对该数据集有效。由于该比赛是图相关的，所以就需要到图相关的SOTA模型网站搜索方案，在这里推荐两个网址，可以找到学术界较新的方案：  

[Leaderboards | Open Graph Benchmark (stanford.edu)](https://ogb.stanford.edu/docs/leader_overview/)

[Browse the State-of-the-Art in Machine Learning | Papers With Code](https://paperswithcode.com/sota)

第一个网站是专门为图相关任务的，Graph-level、Link-level和Node-level的任务与数据集都有，我在其中找到与此次比赛最相关的数据集，然后使用该数据集的SOTA模型，确实提了些分。

第二个网站是所有任务都有的，包括CV、NLP等各种。

### 方案使用

接下来就是将搜索到的方案使用到比赛的代码中，简单点可以直接改模型部分，也可以整体重写，比较耗时间。咱们不是专业的比赛的，除非有积累，可以拿自己以前的某个代码改一改，少花点时间取得较好的效果。  

搜索到的方案可能大多数是无用方案，再相似的数据集它也不是同一个，所以方案需要多试，试的过程中一定要做好记录，以防有效方案被忘记了。  

方案试的差不多了，就定下一套方案下来。

方案的选取需要合理，主要是能够相对于baseline有一个level上的提升，或者更明显的，能够让你当前名次在前排。

后续开始使用Trick或其它办法上分，下面分享一些本人比赛中使用的Trick。

## Trick分享

### 多目标训练

该Trick可能只适用于知识图谱Embedding中的个别模型。具体来说，该任务为链接预测的尾实体预测任务，即给定头实体和关系来预测尾实体。但是所有的实体都是在同一组embedding层中，可以使用尾实体和关系来预测头实体，也可以使用头实体和尾实体来预测关系，这样可以增强知识图谱的结构表示。本质上来说属于一种数据增强。

### 模型集成

该部分分为结果集成和模型预测的集成。由于本人也没有使用过集成，所以只使用最简单的集成方式。

结果集成，训练出多个模型，分别做预测，对预测的结果进行处理，我在使用结果集成的时候，只是使用了简单的投票法。

##### 模型预测集成

模型预测集成我是直接把几个模型的forward输出的logits直接相加，有一定的效果。  

另外一种为交叉验证，教程验证主要是数据集的划分，这里分享一下。  

https://zh-v2.d2l.ai/ 搜交叉验证就会有。

```python
# 由于我的数据只有三元组，故都用x表示，若有label（y），可以加
def get_l_fold_data(k, i, x):
    fold_size = x.shape[0] //k
    x_train = None
    for j in range(k):
        idx = slice(j*fold_size, (j+1)*fold_size)
        x_part = x[idx]
        if j==i:
            x_valid = x_part
        elif x_train is None:
            x_train = x_part
        else:
            x_train = torch.cat([x_train,x_part],0)
    return x_train,x_valid
```

### 对抗训练

来自https://www.csdn.net/tags/MtTaAg3sMDE4MjMyLWJsb2cO0O0O.html

```python
# 初始化 train process
fgm = FGM(model)
for batch_input, batch_label in data:
    # 正常训练
    loss = model(batch_input, batch_label)
    loss.backward() # 反向传播，得到正常的grad
    # 对抗训练
    fgm.attack() # 在embedding上添加对抗扰动
    loss_adv = model(batch_input, batch_label)
    loss_adv.backward() # 反向传播，并在正常的grad基础上，累加对抗训练的梯度
    fgm.restore() # 恢复embedding参数
    # 梯度下降，更新参数
    optimizer.step()
    model.zero_grad()
```

```python
# FGM.py

import torch
class FGM():
    def __init__(self, model):
        self.model = model
        self.backup = {}

    def attack(self, epsilon=1., emb_name='emb.'):
        # emb_name这个参数要换成你模型中embedding的参数名
        for name, param in self.model.named_parameters():
            if param.requires_grad and emb_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0 and not torch.isnan(norm):
                    r_at = epsilon * param.grad / norm
                    param.data.add_(r_at)

    def restore(self, emb_name='emb.'):
        # emb_name这个参数要换成你模型中embedding的参数名
        for name, param in self.model.named_parameters():
            if param.requires_grad and emb_name in name: 
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}
```

## Early stoping防止过拟合

```python
import numpy as np

class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""
    def __init__(self,  patience=40, verbose=False, delta=0):
        """
        Args:
            save_path : 模型保存文件夹
            patience (int): How long to wait after last time validation loss improved.
                            Default: 7
            verbose (bool): If True, prints a message for each validation loss improvement.
                            Default: False
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
                            Default: 0
        """
        # self.save_path = save_path
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta

    def __call__(self, val_MRR):

        score = val_MRR

        if self.best_score is None:
            self.best_score = score
            #self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            # print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                print("Early stopping start.")
                self.early_stop = True
        else:
            self.best_score = score
            #self.save_checkpoint(val_loss, model)
            self.counter = 0

    # def save_checkpoint(self, val_loss, model):
    #     '''Saves model when validation loss decrease.'''
    #     if self.verbose:
    #         print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
    #     path = os.path.join(self.save_path, 'best_network.pth')
    #     torch.save(model.state_dict(), path)	# 这里会存储迄今最优模型的参数
    #     self.val_loss_min = val_loss
```

```python
# 使用
early_stopping = EarlyStopping()
for e in range(NUM_EPOCH):
    loss = train()
    acc = valid()
    early_stopping(valid["MRR"])
    
    if early_stopping.early_stop:
    	break  # 跳出迭代，结束训练
```

### 正则防止过拟合

在我的模型中，加正则能起到明显提分的作用。正则可以在optimizer中直接加weight_decay，也可以在loss之后加上。我采用的是在loss之后加上的办法，然后统一求梯度，更新参数。

### 学习率衰减

这个也是使用后有明显提分的项，分享一下代码。

```python
def adjust_learning_rate(self, learning_rate, optimizer, epoch):
    """decrease the learning rate at 100 and 150 epoch"""
    lr = learning_rate
    if epoch <= 9 and lr > 0.1:
        # warm-up training for large minibatch
        lr = 0.1 + (self.lr - 0.1) * epoch / 10.
    if epoch >= 100:
        lr /= 10
    if epoch >= 150:
        lr /= 10
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
        
# 100和150可调整，在网络训练基本稳定后即可调整学习率学习到更精细的东西
# 使用为在每个epoch的开始，传入初始学习率、优化器和当前的epoch数
```

## 总结

以上就是本次参赛提分的几个关键点，其它的就靠调参和运气了，总的来说通过比赛学习到的知识比平时没有目的的学习要多得多，有时间有精力有兴趣的多多参赛~
